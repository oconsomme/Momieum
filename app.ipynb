{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debebcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from flask)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from flask) (3.1.2)\n",
      "Collecting itsdangerous>=2.1.2 (from flask)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from flask)\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from flask) (6.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from importlib-metadata>=3.6.0->flask) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.7/99.7 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 226.7/226.7 kB 7.0 MB/s eta 0:00:00\n",
      "Installing collected packages: Werkzeug, itsdangerous, click, blinker, flask\n",
      "Successfully installed Werkzeug-3.0.1 blinker-1.7.0 click-8.1.7 flask-3.0.0 itsdangerous-2.1.2\n",
      "Collecting flask-ngrok\n",
      "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
      "Requirement already satisfied: Flask>=0.8 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from flask-ngrok) (3.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from flask-ngrok) (2.31.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->flask-ngrok) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->flask-ngrok) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->flask-ngrok) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->flask-ngrok) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from click>=8.1.3->Flask>=0.8->flask-ngrok) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask>=0.8->flask-ngrok) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (2.1.3)\n",
      "Installing collected packages: flask-ngrok\n",
      "Successfully installed flask-ngrok-0.0.25\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "^C\n",
      "Requirement already satisfied: pillow in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (10.1.0)\n",
      "Collecting flask-cors\n",
      "  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: Flask>=0.9 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from flask-cors) (3.0.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.9->flask-cors) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.9->flask-cors) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.9->flask-cors) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.9->flask-cors) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Flask>=0.9->flask-cors) (6.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from click>=8.1.3->Flask>=0.9->flask-cors) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask>=0.9->flask-cors) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-cors) (2.1.3)\n",
      "Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Installing collected packages: flask-cors\n",
      "Successfully installed flask-cors-4.0.0\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.0.1.tar.gz (731 kB)\n",
      "     ---------------------------------------- 0.0/731.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 731.8/731.8 kB 15.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from pyngrok) (6.0.1)\n",
      "Building wheels for collected packages: pyngrok\n",
      "  Building wheel for pyngrok (setup.py): started\n",
      "  Building wheel for pyngrok (setup.py): finished with status 'done'\n",
      "  Created wheel for pyngrok: filename=pyngrok-7.0.1-py3-none-any.whl size=21154 sha256=a06187afbe69036ef99f01bdcbc08e0ae3f51db4fbae9641d68aab8401e25b4c\n",
      "  Stored in directory: c:\\users\\aischool\\appdata\\local\\pip\\cache\\wheels\\fc\\42\\db\\02ccb3c98672dbcc993955a78d77814907b78adcf67fca93bd\n",
      "Successfully built pyngrok\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install flask\n",
    "!pip install flask-ngrok\n",
    "!pip install torch torchvision\n",
    "!pip install pillow\n",
    "!pip install pyngrok\n",
    "!pip install flask-cors\n",
    "\n",
    "!pip install PyPDF2\n",
    "\n",
    "!pip install openai==0.28\n",
    "!pip install --upgrade typing_extensions\n",
    "!pip install --upgrade torch\n",
    "\n",
    "!pip install flask flask_sqlalchemy cx_Oracle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fe3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# YOLOv5 GitHub 저장소를 복제합니다.\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/ultralytics/yolov5.git\"], check=True)\n",
    "\n",
    "# 필요한 라이브러리를 설치합니다.\n",
    "subprocess.run([\"pip\", \"install\", \"-r\", \"yolov5/requirements.txt\"], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, url_for, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import logging\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# 이미지가 저장될 디렉토리 설정\n",
    "UPLOAD_FOLDER = 'C:/Users/aischool/FlaskTest/static/uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 파일 최대 크기를 16MB로 제한\n",
    "\n",
    "# 로깅 설정\n",
    "app.logger.setLevel(logging.DEBUG)\n",
    "app.debug = False\n",
    "\n",
    "# YOLOv5 모델 로드\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='C:/Users/aischool/FlaskTest/yolov5/runs/train/best(2).pt')\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def generate_unique_filename(filename):\n",
    "    counter = 1\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    while os.path.exists(os.path.join(UPLOAD_FOLDER, new_filename)):\n",
    "        counter += 1\n",
    "        new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    return new_filename\n",
    "\n",
    "def process_image(image_path):\n",
    "    results = model(image_path)\n",
    "    results_data = results.pandas().xyxy[0]\n",
    "    return results_data.to_json(orient=\"records\")\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    image_url = url_for('static', filename='images/no-image.jpg')\n",
    "    return render_template('index.html', image_url=image_url)\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        app.logger.error('No file part in the request')\n",
    "        return jsonify({'message': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        app.logger.error('No selected file for uploading')\n",
    "        return jsonify({'message': 'No selected file'}), 400\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = generate_unique_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "        results_json = process_image(file_path)\n",
    "        json_path = os.path.join(app.config['UPLOAD_FOLDER'], f\"{filename}.json\")\n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(results_json)\n",
    "\n",
    "        return jsonify({\n",
    "            'message': 'File uploaded and processed successfully',\n",
    "            'file_path': url_for('static', filename=os.path.join('uploads', filename)),\n",
    "            'json_path': url_for('static', filename=os.path.join('uploads', f\"{filename}.json\"))\n",
    "        }), 200\n",
    "\n",
    "    else:\n",
    "        app.logger.error('File type not allowed')\n",
    "        return jsonify({'message': 'File type not allowed'}), 400\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27bff90",
   "metadata": {},
   "source": [
    "--이하 논문전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df328380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05654cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 특수 문자 제거\n",
    "    text = re.sub(r'[^a-zA-Z0-9가-힣\\s]', '', text)\n",
    "\n",
    "    # 줄바꿈 및 여러 공백을 하나의 공백으로 변환\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # 문장 분리 (간단한 예시, 보다 정교한 방법 적용 가능)\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    text = ' '.join(sentences)\n",
    "\n",
    "    # 대소문자 정규화 (예: 모든 텍스트를 소문자로 변환)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "def process_pdfs_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            preprocessed_text = preprocess_text(text)\n",
    "\n",
    "            # 결과를 txt 파일로 저장\n",
    "            output_path = os.path.join(folder_path, filename.replace('.pdf', '.txt'))\n",
    "            with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(preprocessed_text)\n",
    "            print(f\"Processed and saved: {output_path}\")\n",
    "\n",
    "folder_path = 'C:/Users/aischool/Downloads/thesis'\n",
    "process_pdfs_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6790f",
   "metadata": {},
   "source": [
    "--전처리 된 각각의 논문 txt를 하나로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_txt_files(folder_path, output_filename):\n",
    "    with open(os.path.join(folder_path, output_filename), 'w', encoding='utf-8') as output_file:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.txt') and filename != output_filename:\n",
    "                with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as input_file:\n",
    "                    output_file.write(input_file.read() + \"\\n\\n\")\n",
    "\n",
    "folder_path = 'C:/Users/aischool/Downloads/thesis'\n",
    "output_filename = 'combined_text.txt'\n",
    "combine_txt_files(folder_path, output_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05df23c",
   "metadata": {},
   "source": [
    "--전체코드 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f203bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0a0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa92b5fa",
   "metadata": {},
   "source": [
    "## gpt4 turbo interpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import logging\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "import json\n",
    "import openai\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "UPLOAD_FOLDER = 'C:/Users/aischool/FlaskTest/static/uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "app.logger.setLevel(logging.DEBUG)\n",
    "app.debug = False\n",
    "\n",
    "#SQLAlchemy\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'oracle+cx_oracle://Insa4_Spring_final_3:aishcool3@project-db-stu3.smhrd.com:1524/xe'\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='C:/Users/aischool/FlaskTest/yolov5/runs/train/best.pt')\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def generate_unique_filename(filename):\n",
    "    counter = 1\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    while os.path.exists(os.path.join(UPLOAD_FOLDER, new_filename)):\n",
    "        counter += 1\n",
    "        new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    return new_filename\n",
    "\n",
    "def process_image(image_path):\n",
    "    results = model(image_path)\n",
    "    results_data = results.pandas().xyxy[0]\n",
    "    return results_data.to_json(orient=\"records\")\n",
    "\n",
    "def convert_json_to_natural_language(json_data):\n",
    "    natural_language_output = []\n",
    "    for item in json_data:\n",
    "        description = f\"객체 '{item['name']}'가 감지되었습니다. 신뢰도는 {item['confidence']*100:.2f}%입니다.\"\n",
    "        natural_language_output.append(description)\n",
    "    return ' '.join(natural_language_output)\n",
    "\n",
    "\n",
    "def gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    # 참고 파일에서 텍스트 읽기\n",
    "    with open(reference_file_path, 'r', encoding='utf-8') as file:\n",
    "        reference_text = file.read()\n",
    "\n",
    "    # GPT-4에 전달할 프롬프트 생성\n",
    "    prompt = reference_text + \"\\n\\n\" + natural_language_data\n",
    "\n",
    "    # 새로운 API 인터페이스를 사용하여 GPT-4에 요청\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",  \n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "\n",
    "\n",
    "#SQLAlchemy\n",
    "\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class TestResult(db.Model):\n",
    "    __tablename__ = 'TB_TEST'\n",
    "    TEST_IDX = db.Column(db.Integer, primary_key=True)\n",
    "    TEST_RESULT = db.Column(db.CLOB)\n",
    "    TESTED_AT = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    TEST_TYPE = db.Column(db.String(20))\n",
    "    MEM_ID = db.Column(db.String(30))\n",
    "    #CREATED_AT = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "\n",
    "    def __init__(self, TEST_RESULT, TEST_TYPE, MEM_ID):\n",
    "        self.TEST_RESULT = TEST_RESULT\n",
    "        self.TEST_TYPE = TEST_TYPE\n",
    "        self.MEM_ID = MEM_ID\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    image_url = url_for('static', filename='images/no-image.jpg')\n",
    "    return 'HTP JSON 모델 서비스'\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        app.logger.error('No file part in the request')\n",
    "        return jsonify({'message': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        app.logger.error('No selected file for uploading')\n",
    "        return jsonify({'message': 'No selected file'}), 400\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = generate_unique_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "        results_json = process_image(file_path)\n",
    "        json_path = os.path.join(app.config['UPLOAD_FOLDER'], f\"{filename}.json\")\n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(results_json)\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        natural_language_data = convert_json_to_natural_language(json_data)\n",
    "\n",
    "        api_key = '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'\n",
    "        reference_file_path = 'C:/Users/aischool/FlaskTest/static/thesis/combined_text2.txt'\n",
    "        gpt_result = gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path)\n",
    "\n",
    "        gpt_result_path = os.path.join(UPLOAD_FOLDER, f\"{filename}_gpt_result.txt\")\n",
    "        with open(gpt_result_path, 'w', encoding='utf-8') as result_file:\n",
    "            result_file.write(gpt_result)\n",
    "\n",
    "        try:\n",
    "            new_test_result = TestResult(\n",
    "                TEST_RESULT=gpt_result,\n",
    "                TEST_TYPE='HTP',\n",
    "                MEM_ID='mem_id 01'  # 실제 회원 ID로 대체\n",
    "            )\n",
    "            db.session.add(new_test_result)\n",
    "            db.session.commit()\n",
    "        except Exception as e:\n",
    "            app.logger.error(f\"데이터베이스 오류: {e}\")\n",
    "            return jsonify({'message': '데이터베이스 오류'}), 500\n",
    "\n",
    "        return jsonify({\n",
    "            'message': 'File uploaded and processed successfully',\n",
    "            'gpt_result_path': url_for('static', filename=os.path.join('uploads', f\"{filename}_gpt_result.txt\"))\n",
    "        }), 200\n",
    "        \n",
    "    else:\n",
    "        app.logger.error('File type not allowed')\n",
    "        return jsonify({'message': 'File type not allowed'}), 400\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\aischool/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-11-1 Python-3.10.9 torch-2.1.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7136884 parameters, 0 gradients, 16.2 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5011\n",
      " * Running on http://192.168.20.6:5011\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Nov/2023 15:31:56] \"POST /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Nov/2023 15:32:18] \"POST /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Nov/2023 15:32:18] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import logging\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "import json\n",
    "import openai\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "import io\n",
    "from PIL import Image\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "UPLOAD_FOLDER = 'C:/Users/aischool/FlaskTest/static/uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "app.logger.setLevel(logging.DEBUG)\n",
    "app.debug = False\n",
    "\n",
    "# SQLAlchemy 설정\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'oracle+cx_oracle://Insa4_Spring_final_3:aishcool3@project-db-stu3.smhrd.com:1524/xe'\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='C:/Users/aischool/FlaskTest/yolov5/runs/train/best.pt')\n",
    "\n",
    "# 파일 확장자 검사\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "# 유니크한 파일명 생성\n",
    "def generate_unique_filename(filename):\n",
    "    counter = 1\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    while os.path.exists(os.path.join(UPLOAD_FOLDER, new_filename)):\n",
    "        counter += 1\n",
    "        new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    return new_filename\n",
    "\n",
    "# 이미지 처리\n",
    "def process_image(blob_data):\n",
    "    results = model(image_path)\n",
    "    results_data = results.pandas().xyxy[0]\n",
    "    return results_data.to_json(orient=\"records\")\n",
    "\n",
    "# JSON 데이터를 자연어로 변환\n",
    "def convert_json_to_natural_language(json_data):\n",
    "    natural_language_output = []\n",
    "    for item in json_data:\n",
    "        description = f\"객체 '{item['name']}'가 감지되었습니다. 신뢰도는 {item['confidence']*100:.2f}%입니다.\"\n",
    "        natural_language_output.append(description)\n",
    "    return ' '.join(natural_language_output)\n",
    "\n",
    "# 이미지를 BLOB으로 변환\n",
    "def convert_image_to_blob(image_path):\n",
    "    with open(image_path, 'rb') as file:\n",
    "        blob_data = file.read()\n",
    "    return blob_data\n",
    "\n",
    "# GPT-4 해석\n",
    "def gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path):\n",
    "    openai.api_key = api_key\n",
    "    with open(reference_file_path, 'r', encoding='utf-8') as file:\n",
    "        reference_text = file.read()\n",
    "    prompt = reference_text + \"\\n\\n\" + natural_language_data\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",  \n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# SQLAlchemy 모델\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class TestResult(db.Model):\n",
    "    __tablename__ = 'TB_TEST'\n",
    "    TEST_IDX = db.Column(db.Integer, primary_key=True)\n",
    "    TEST_RESULT = db.Column(db.CLOB)\n",
    "    TESTED_AT = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    TEST_TYPE = db.Column(db.String(20))\n",
    "    MEM_ID = db.Column(db.String(30))\n",
    "    TEST_IMG = db.Column(db.LargeBinary)  # BLOB 필드 추가\n",
    "\n",
    "    def __init__(self, TEST_RESULT, TEST_TYPE, MEM_ID, TEST_IMG):\n",
    "        self.TEST_RESULT = TEST_RESULT\n",
    "        self.TEST_TYPE = TEST_TYPE\n",
    "        self.MEM_ID = MEM_ID\n",
    "        self.TEST_IMG = TEST_IMG\n",
    "\n",
    "# 메인 페이지\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'HTP JSON 모델 서비스'\n",
    "\n",
    "# 파일 업로드\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        app.logger.error('No file part in the request')\n",
    "        return jsonify({'message': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        app.logger.error('No selected file for uploading')\n",
    "        return jsonify({'message': 'No selected file'}), 400\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = generate_unique_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "        results_json = process_image(file_path)\n",
    "        json_path = os.path.join(app.config['UPLOAD_FOLDER'], f\"{filename}.json\")\n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(results_json)\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        natural_language_data = convert_json_to_natural_language(json_data)\n",
    "\n",
    "        api_key = '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'  # 여기에 OpenAI API 키를 입력하세요.\n",
    "        reference_file_path = 'C:/Users/aischool/FlaskTest/static/thesis/combined_text2.txt'\n",
    "        gpt_result = gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path)\n",
    "\n",
    "        # 이미지를 BLOB으로 변환\n",
    "        image_blob = convert_image_to_blob(file_path)\n",
    "\n",
    "        # 데이터베이스에 저장\n",
    "        try:\n",
    "            new_test_result = TestResult(\n",
    "                TEST_RESULT=gpt_result,\n",
    "                TEST_TYPE='HTP',\n",
    "                MEM_ID='mem_id 01',  # 실제 회원 ID로 대체\n",
    "                TEST_IMG=image_blob  # 이미지 BLOB 저장\n",
    "            )\n",
    "            db.session.add(new_test_result)\n",
    "            db.session.commit()\n",
    "        except Exception as e:\n",
    "            app.logger.error(f\"데이터베이스 오류: {e}\")\n",
    "            return jsonify({'message': '데이터베이스 오류'}), 500\n",
    "\n",
    "        return jsonify({'message': 'File uploaded and processed successfully'}), 200\n",
    "\n",
    "    else:\n",
    "        app.logger.error('File type not allowed')\n",
    "        return jsonify({'message': 'File type not allowed'}), 400\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6655a1a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.google_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# YOLOv7 모듈 임포트 (예시, 실제 경로는 YOLOv7 설치에 따라 다를 수 있음)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myolov7\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attempt_load  \u001b[38;5;66;03m# 모델 로드 함수\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 경로 추가\u001b[39;00m\n\u001b[0;32m     20\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/aischool/FlaskTest/yolov7/utils\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\FlaskTest\\yolov7\\models\\experimental.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv, DWConv\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgoogle_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attempt_download\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCrossConv\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Cross Convolution Downsample\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, c1, c2, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, g\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, e\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, shortcut\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# ch_in, ch_out, kernel, stride, groups, expansion, shortcut\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils.google_utils'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import logging\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "import json\n",
    "import openai\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64  # base64 인코딩을 위한 모듈\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "UPLOAD_FOLDER = 'C:/Users/aischool/FlaskTest/static/uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "app.logger.setLevel(logging.DEBUG)\n",
    "app.debug = False\n",
    "\n",
    "# SQLAlchemy 설정\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'oracle+cx_oracle://Insa4_Spring_final_3:aishcool3@project-db-stu3.smhrd.com:1524/xe'\n",
    "\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='C:/Users/aischool/FlaskTest/yolov5/runs/train/best.pt')\n",
    "\n",
    "# YOLOv7 모델 로딩 코드로 변경\n",
    "#model = torch.hub.load('WongKinYiu/yolov7', 'custom', path='C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt')\n",
    "#model = attempt_load('C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# 파일 확장자 검사\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "# 유니크한 파일명 생성\n",
    "def generate_unique_filename(filename):\n",
    "    counter = 1\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    while os.path.exists(os.path.join(UPLOAD_FOLDER, new_filename)):\n",
    "        counter += 1\n",
    "        new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    return new_filename\n",
    "\n",
    "# 이미지 처리\n",
    "def process_image(image_input):\n",
    "    if isinstance(image_input, str):  # 파일 경로의 경우\n",
    "        image_path = image_input\n",
    "    else:  # BLOB 데이터의 경우\n",
    "        image_stream = io.BytesIO(image_input)\n",
    "        image = Image.open(image_stream)\n",
    "        image_path = image\n",
    "\n",
    "    results = model(image_path)\n",
    "    results_data = results.pandas().xyxy[0]\n",
    "    return results_data.to_json(orient=\"records\")\n",
    "\n",
    "# JSON 데이터를 자연어로 변환\n",
    "def convert_json_to_natural_language(json_data):\n",
    "    natural_language_output = []\n",
    "    for item in json_data:\n",
    "        description = f\"객체 '{item['name']}'가 감지되었습니다. 신뢰도는 {item['confidence']*100:.2f}%입니다.\"\n",
    "        natural_language_output.append(description)\n",
    "    return ' '.join(natural_language_output)\n",
    "\n",
    "# 이미지를 BLOB으로 변환\n",
    "def convert_image_to_blob(image_path):\n",
    "    with open(image_path, 'rb') as file:\n",
    "        blob_data = file.read()\n",
    "    return blob_data\n",
    "\n",
    "# GPT-4 해석\n",
    "def gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path):\n",
    "    openai.api_key = api_key\n",
    "    with open(reference_file_path, 'r', encoding='utf-8') as file:\n",
    "        reference_text = file.read()\n",
    "    prompt = reference_text + \"\\n\\n\" + natural_language_data\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",  \n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# SQLAlchemy 모델\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class TestResult(db.Model):\n",
    "    __tablename__ = 'TB_TEST'\n",
    "    TEST_IDX = db.Column(db.Integer, primary_key=True)\n",
    "    TEST_RESULT = db.Column(db.CLOB)\n",
    "    TESTED_AT = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    TEST_TYPE = db.Column(db.String(20))\n",
    "    USERNAME = db.Column(db.String(30))\n",
    "    TEST_IMG = db.Column(db.LargeBinary)  # BLOB 필드 추가\n",
    "\n",
    "    def __init__(self, TEST_RESULT, TEST_TYPE, USERNAME, TEST_IMG):\n",
    "        self.TEST_RESULT = TEST_RESULT\n",
    "        self.TEST_TYPE = TEST_TYPE\n",
    "        self.USERNAME = USERNAME\n",
    "        self.TEST_IMG = TEST_IMG\n",
    "\n",
    "# 메인 페이지\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'HTP JSON 모델 서비스'\n",
    "\n",
    "# 파일 업로드\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        app.logger.error('No file part in the request')\n",
    "        return jsonify({'message': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        app.logger.error('No selected file for uploading')\n",
    "        return jsonify({'message': 'No selected file'}), 400\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = generate_unique_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "        # 이미지 처리\n",
    "        results_json = process_image(file_path)\n",
    "\n",
    "        json_path = os.path.join(app.config['UPLOAD_FOLDER'], f\"{filename}.json\")\n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(results_json)\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        natural_language_data = convert_json_to_natural_language(json_data)\n",
    "\n",
    "        api_key = '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'  # OpenAI API 키를 여기에 입력하세요.\n",
    "        reference_file_path = 'C:/Users/aischool/FlaskTest/static/thesis/combined_text2.txt'\n",
    "        gpt_result = gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path)\n",
    "\n",
    "\n",
    "\n",
    "        # 이미지를 BLOB으로 변환\n",
    "        image_blob = convert_image_to_blob(file_path)\n",
    "\n",
    "        # 데이터베이스에 저장\n",
    "        try:\n",
    "            new_test_result = TestResult(\n",
    "                TEST_RESULT=gpt_result,\n",
    "                TEST_TYPE='HTP',\n",
    "                USERNAME='hsc',  # 실제 회원 ID로 대체\n",
    "                TEST_IMG=image_blob  # 이미지 BLOB 저장\n",
    "            )\n",
    "            db.session.add(new_test_result)\n",
    "            db.session.commit()\n",
    "        except Exception as e:\n",
    "            app.logger.error(f\"데이터베이스 오류: {e}\")\n",
    "            return jsonify({'message': '데이터베이스 오류'}), 500\n",
    "\n",
    "        return jsonify({'message': 'File uploaded and processed successfully'}), 200\n",
    "\n",
    "    else:\n",
    "        app.logger.error('File type not allowed')\n",
    "        return jsonify({'message': 'File type not allowed'}), 400\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fecb64-7409-415e-9b69-0780593477f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.16.1-cp38-cp38-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.1 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torch==2.1.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torch==2.1.1->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torch==2.1.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torch==2.1.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torch==2.1.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from torch==2.1.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from jinja2->torch==2.1.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aischool\\.conda\\envs\\yolov7\\lib\\site-packages (from sympy->torch==2.1.1->torchvision) (1.3.0)\n",
      "Using cached torchvision-0.16.1-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba9b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/WongKinYiu/yolov7/zipball/main\" to C:\\Users\\aischool/.cache\\torch\\hub\\main.zip\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    282280  models.yolo.IDetect                     [47, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "C:\\Users\\aischool\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 415 layers, 37444680 parameters, 37444680 gradients, 105.9 GFLOPS\n",
      "\n",
      "YOLOR  2023-11-27 torch 2.1.1+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding autoShape... \n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5011\n",
      " * Running on http://192.168.21.1:5011\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "[2023-11-27 17:39:13,669] ERROR in 3677239747: 데이터베이스 오류: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
      "데이터베이스 오류: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
      "127.0.0.1 - - [27/Nov/2023 17:39:13] \"\u001b[35m\u001b[1mPOST /upload HTTP/1.1\u001b[0m\" 500 -\n",
      "[2023-11-27 17:40:03,966] ERROR in 3677239747: 데이터베이스 오류: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
      "데이터베이스 오류: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
      "127.0.0.1 - - [27/Nov/2023 17:40:03] \"\u001b[35m\u001b[1mPOST /upload HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import logging\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "import json\n",
    "import openai\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "import io\n",
    "# import utils\n",
    "from PIL import Image\n",
    "import base64  # base64 인코딩을 위한 모듈\n",
    "import sys\n",
    "from sqlalchemy import desc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "UPLOAD_FOLDER = 'C:/Users/aischool/FlaskTest/static/uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "app.logger.setLevel(logging.DEBUG)\n",
    "app.debug = False\n",
    "\n",
    "# SQLAlchemy 설정\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'oracle+cx_oracle://Insa4_Spring_final_3:aishcool3@project-db-stu3.smhrd.com:1524/xe'\n",
    "\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# YOLOv7 모델 로드\n",
    "def load_yolov7_model(model_path):\n",
    "    # torch.hub를 사용하여 YOLOv7의 GitHub 저장소에서 모델을 로드\n",
    "    model = torch.hub.load('WongKinYiu/yolov7', 'custom', model_path, force_reload=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "# YOLOv7 모델 로딩 코드로 변경\n",
    "#model = torch.hub.load('WongKinYiu/yolov7', 'custom', path='C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt')\n",
    "#model = attempt_load('C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt', map_location=torch.device('cpu'))\n",
    "model = load_yolov7_model('C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt')\n",
    "\n",
    "# 파일 확장자 검사\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "# 유니크한 파일명 생성\n",
    "def generate_unique_filename(filename):\n",
    "    counter = 1\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    while os.path.exists(os.path.join(UPLOAD_FOLDER, new_filename)):\n",
    "        counter += 1\n",
    "        new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    return new_filename\n",
    "\n",
    "# 이미지 처리\n",
    "def process_image(image_input):\n",
    "    if isinstance(image_input, str):  # 파일 경로의 경우\n",
    "        image_path = image_input\n",
    "    else:  # BLOB 데이터의 경우\n",
    "        image_stream = io.BytesIO(image_input)\n",
    "        image = Image.open(image_stream)\n",
    "        image_path = image\n",
    "\n",
    "    results = model(image_path)\n",
    "    results_data = results.pandas().xyxy[0]\n",
    "    return results_data.to_json(orient=\"records\")\n",
    "\n",
    "# JSON 데이터를 자연어로 변환\n",
    "def convert_json_to_natural_language(json_data):\n",
    "    natural_language_output = []\n",
    "    for item in json_data:\n",
    "        description = f\"객체 '{item['name']}'가 감지되었습니다. 신뢰도는 {item['confidence']*100:.2f}%입니다.\"\n",
    "        natural_language_output.append(description)\n",
    "    return ' '.join(natural_language_output)\n",
    "\n",
    "# 이미지를 BLOB으로 변환\n",
    "def convert_image_to_blob(image_path):\n",
    "    with open(image_path, 'rb') as file:\n",
    "        blob_data = file.read()\n",
    "    return blob_data\n",
    "\n",
    "# GPT-4 해석\n",
    "def gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path):\n",
    "    openai.api_key = api_key\n",
    "    with open(reference_file_path, 'r', encoding='utf-8') as file:\n",
    "        reference_text = file.read()\n",
    "    prompt = reference_text + \"\\n\\n\" + natural_language_data\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",  \n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# SQLAlchemy 모델\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class TestResult(db.Model):\n",
    "    __tablename__ = 'TB_TEST'\n",
    "    TEST_IDX = db.Column(db.Integer, primary_key=True)\n",
    "    TEST_RESULT = db.Column(db.CLOB)\n",
    "    TESTED_AT = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    TEST_TYPE = db.Column(db.String(20))\n",
    "    USERNAME = db.Column(db.String(30))\n",
    "    TEST_IMG = db.Column(db.LargeBinary)  # BLOB 필드 추가\n",
    "\n",
    "    def __init__(self, TEST_RESULT, TEST_TYPE, USERNAME, TEST_IMG):\n",
    "        self.TEST_RESULT = TEST_RESULT\n",
    "        self.TEST_TYPE = TEST_TYPE\n",
    "        self.USERNAME = USERNAME\n",
    "        self.TEST_IMG = TEST_IMG\n",
    "\n",
    "# 메인 페이지\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'HTP JSON 모델 서비스'\n",
    "\n",
    "# GPT-4를 사용한 챗봇 대화 처리\n",
    "\n",
    "def is_htp_related(message):\n",
    "    \"\"\"\n",
    "    메시지가 HTP 심리검사와 관련이 있는지 확인합니다.\n",
    "    이 함수를 더 정교하게 만들 수 있습니다.\n",
    "    \"\"\"\n",
    "    htp_keywords = [\n",
    "        'HTP', '나무', '집', '사람', '하우스', '트리', '퍼슨',\n",
    "        '심리검사', '가족', '자아', '정서', '감정', '그림', '창의성', \n",
    "        '성격', '자아상', '가정', '안정', '불안', '스트레스', \n",
    "        '대인관계', '환경', '개인성향', '인지', '자기개념', '갈등', \n",
    "        '어댑테이션', '응집성', '대처기술', '자기표현', '내성적', '외향적', \n",
    "        '관계', '응답', '해석', '분석', '심리학', '정신건강', '감정조절', \n",
    "        '자기인식', '반응', '투사', '사회적 상호작용', '사회성', '표현', \n",
    "        '내면세계', '의식', '무의식', '감수성', '창조력', '인격', '정체성'\n",
    "    ]\n",
    "    return any(keyword.lower() in message.lower() for keyword in htp_keywords)\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat_with_bot():\n",
    "    data = request.json\n",
    "    user_message = data.get('message')\n",
    "\n",
    "    if not user_message:\n",
    "        return jsonify({'error': 'No message provided'}), 400\n",
    "\n",
    "    # OpenAI API 키 설정\n",
    "    openai.api_key = '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'\n",
    "\n",
    "    # 사용자의 메시지가 HTP 심리검사와 관련된 주제인지 확인\n",
    "    if not is_htp_related(user_message):\n",
    "        return jsonify({'reply': '저는 HTP 심리검사에 관한 질문에만 답변할 수 있습니다.'}), 200\n",
    "\n",
    "    # GPT-4를 호출하여 사용자 메시지에 대한 응답 생성\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 HTP 심리검사에 대한 전문적인 지식을 가진 상담가입니다. 사용자의 질문에 대해 상냥하고 친절하게, 간결하게 답변하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.3,\n",
    "            presence_penalty=0.0,\n",
    "            frequency_penalty=0.0,\n",
    "            stop=[\"\\n\"]\n",
    "        )\n",
    "\n",
    "        gpt_response = response.choices[0].message['content']\n",
    "        return jsonify({'reply': gpt_response})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "def is_htp_related(message):\n",
    "    # 여기에 HTP 심리검사와 관련된 키워드를 확인하는 로직을 추가하세요\n",
    "    # 예시: \"HTP\", \"나무\", \"집\", \"사람\", \"심리검사\" 등이 포함되었는지 확인\n",
    "    htp_keywords = [\"HTP\", \"나무\", \"집\", \"사람\", \"심리검사\"]\n",
    "    return any(keyword in message for keyword in htp_keywords)\n",
    "\n",
    "\n",
    "\n",
    "# 파일 업로드\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        app.logger.error('No file part in the request')\n",
    "        return jsonify({'message': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        app.logger.error('No selected file for uploading')\n",
    "        return jsonify({'message': 'No selected file'}), 400\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = generate_unique_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "        # 이미지 처리\n",
    "        results_json = process_image(file_path)\n",
    "\n",
    "        json_path = os.path.join(app.config['UPLOAD_FOLDER'], f\"{filename}.json\")\n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(results_json)\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        natural_language_data = convert_json_to_natural_language(json_data)\n",
    "\n",
    "        api_key = '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'  # OpenAI API 키를 여기에 입력하세요.\n",
    "        reference_file_path = 'C:/Users/aischool/FlaskTest/static/thesis/combined_text2.txt'\n",
    "        gpt_result = gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path)\n",
    "\n",
    "\n",
    "\n",
    "        # 이미지를 BLOB으로 변환\n",
    "        image_blob = convert_image_to_blob(file_path)\n",
    "\n",
    "        # 데이터베이스에 저장\n",
    "        try:\n",
    "            new_test_result = TestResult(\n",
    "                TEST_RESULT=gpt_result,\n",
    "                TEST_TYPE='HTP',\n",
    "                USERNAME=request.form['username'],  # 실제 회원 ID로 대체\n",
    "                TEST_IMG=image_blob  # 이미지 BLOB 저장\n",
    "            )\n",
    "            db.session.add(new_test_result)\n",
    "            db.session.commit()\n",
    "        except Exception as e:\n",
    "            app.logger.error(f\"데이터베이스 오류: {e}\")\n",
    "            return jsonify({'message': '데이터베이스 오류'}), 500\n",
    "\n",
    "        return jsonify({'message': 'File uploaded and processed successfully'}), 200\n",
    "\n",
    "    else:\n",
    "        app.logger.error('File type not allowed')\n",
    "        return jsonify({'message': 'File type not allowed'}), 400\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3d3a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aischool\\FlaskTest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 현재 작업 디렉토리 얻기\n",
    "current_working_directory = os.getcwd()\n",
    "print(current_working_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64884ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/WongKinYiu/yolov7/zipball/main\" to C:\\Users\\aischool/.cache\\torch\\hub\\main.zip\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    282280  models.yolo.IDetect                     [47, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "C:\\Users\\aischool\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 415 layers, 37444680 parameters, 37444680 gradients, 105.9 GFLOPS\n",
      "\n",
      "YOLOR  2023-12-4 torch 2.1.1+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding autoShape... \n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5011\n",
      " * Running on http://172.29.96.109:5011\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [04/Dec/2023 13:12:41] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Dec/2023 13:12:41] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import logging\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "import json\n",
    "import openai\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "import io\n",
    "# import utils\n",
    "from PIL import Image\n",
    "import base64  # base64 인코딩을 위한 모듈\n",
    "import sys\n",
    "from sqlalchemy import desc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "UPLOAD_FOLDER = 'C:/Users/aischool/FlaskTest/static/uploads'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "app.logger.setLevel(logging.DEBUG)\n",
    "app.debug = False\n",
    "\n",
    "# SQLAlchemy 설정\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'oracle+cx_oracle://Insa4_Spring_final_3:aishcool3@project-db-stu3.smhrd.com:1524/xe'\n",
    "\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# YOLOv7 모델 로드\n",
    "def load_yolov7_model(model_path):\n",
    "    # torch.hub를 사용하여 YOLOv7의 GitHub 저장소에서 모델을 로드\n",
    "    model = torch.hub.load('WongKinYiu/yolov7', 'custom', model_path, force_reload=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "# YOLOv7 모델 로딩 코드로 변경\n",
    "#model = torch.hub.load('WongKinYiu/yolov7', 'custom', path='C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt')\n",
    "#model = attempt_load('C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt', map_location=torch.device('cpu'))\n",
    "model = load_yolov7_model('C:/Users/aischool/FlaskTest/yolov7/runs/train/best.pt')\n",
    "\n",
    "# 파일 확장자 검사\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "# 유니크한 파일명 생성\n",
    "def generate_unique_filename(filename):\n",
    "    counter = 1\n",
    "    name, extension = os.path.splitext(filename)\n",
    "    new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    while os.path.exists(os.path.join(UPLOAD_FOLDER, new_filename)):\n",
    "        counter += 1\n",
    "        new_filename = secure_filename(f\"{name}_{counter}{extension}\")\n",
    "    return new_filename\n",
    "\n",
    "# 이미지 처리\n",
    "def process_image(image_input):\n",
    "    if isinstance(image_input, str):  # 파일 경로의 경우\n",
    "        image_path = image_input\n",
    "    else:  # BLOB 데이터의 경우\n",
    "        image_stream = io.BytesIO(image_input)\n",
    "        image = Image.open(image_stream)\n",
    "        image_path = image\n",
    "\n",
    "    results = model(image_path)\n",
    "    results_data = results.pandas().xyxy[0]\n",
    "    return results_data.to_json(orient=\"records\")\n",
    "\n",
    "# JSON 데이터를 자연어로 변환\n",
    "def convert_json_to_natural_language(json_data):\n",
    "    natural_language_output = []\n",
    "    for item in json_data:\n",
    "        description = f\"객체 '{item['name']}'가 감지되었습니다. 신뢰도는 {item['confidence']*100:.2f}%입니다.\"\n",
    "        natural_language_output.append(description)\n",
    "    return ' '.join(natural_language_output)\n",
    "\n",
    "# 이미지를 BLOB으로 변환\n",
    "def convert_image_to_blob(image_path):\n",
    "    with open(image_path, 'rb') as file:\n",
    "        blob_data = file.read()\n",
    "    return blob_data\n",
    "\n",
    "# GPT-4 해석\n",
    "def gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path):\n",
    "    openai.api_key = api_key\n",
    "    with open(reference_file_path, 'r', encoding='utf-8') as file:\n",
    "        reference_text = file.read()\n",
    "    prompt = reference_text + \"\\n\\n\" + natural_language_data\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",  \n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# SQLAlchemy 모델\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class TestResult(db.Model):\n",
    "    __tablename__ = 'TB_TEST'\n",
    "    TEST_IDX = db.Column(db.Integer, primary_key=True)\n",
    "    TEST_RESULT = db.Column(db.CLOB)\n",
    "    TESTED_AT = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    TEST_TYPE = db.Column(db.String(20))\n",
    "    USERNAME = db.Column(db.String(30))\n",
    "    TEST_IMG = db.Column(db.LargeBinary)  # BLOB 필드 추가\n",
    "\n",
    "    def __init__(self, TEST_RESULT, TEST_TYPE, USERNAME, TEST_IMG):\n",
    "        self.TEST_RESULT = TEST_RESULT\n",
    "        self.TEST_TYPE = TEST_TYPE\n",
    "        self.USERNAME = USERNAME\n",
    "        self.TEST_IMG = TEST_IMG\n",
    "\n",
    "# 메인 페이지\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'HTP JSON 모델 서비스'\n",
    "\n",
    "# GPT-4를 사용한 챗봇 대화 처리\n",
    "\n",
    "def is_htp_related(message):\n",
    "    \"\"\"\n",
    "    메시지가 HTP 심리검사와 관련이 있는지 확인합니다.\n",
    "    이 함수를 더 정교하게 만들 수 있습니다.\n",
    "    \"\"\"\n",
    "    htp_keywords = [\n",
    "        'HTP', '나무', '집', '사람', '하우스', '트리', '퍼슨',\n",
    "        '심리검사', '가족', '자아', '정서', '감정', '그림', '창의성', \n",
    "        '성격', '자아상', '가정', '안정', '불안', '스트레스', \n",
    "        '대인관계', '환경', '개인성향', '인지', '자기개념', '갈등', \n",
    "        '어댑테이션', '응집성', '대처기술', '자기표현', '내성적', '외향적', \n",
    "        '관계', '응답', '해석', '분석', '심리학', '정신건강', '감정조절', \n",
    "        '자기인식', '반응', '투사', '사회적 상호작용', '사회성', '표현', \n",
    "        '내면세계', '의식', '무의식', '감수성', '창조력', '인격', '정체성'\n",
    "    ]\n",
    "    return any(keyword.lower() in message.lower() for keyword in htp_keywords)\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat_with_bot():\n",
    "    data = request.json\n",
    "    user_message = data.get('message')\n",
    "    username = data.get('username')  # 챗봇 대화에서 사용자 ID 사용\n",
    "\n",
    "    if not user_message:\n",
    "        return jsonify({'error': 'No message provided'}), 400\n",
    "\n",
    "    # 사용자의 메시지가 HTP 심리검사와 관련된 주제인지 확인\n",
    "    if not is_htp_related(user_message):\n",
    "        return jsonify({'reply': '저는 HTP 심리검사에 관한 질문에만 답변할 수 있습니다.'}), 200\n",
    "\n",
    "    # GPT-4 해석 결과를 참조하여 추가 정보 제공\n",
    "    additional_info = gpt4_interpretations.get(username, \"최근 분석 정보가 없습니다.\")\n",
    "\n",
    "    # 'combined_text2.txt' 파일의 내용을 읽어 additional_info2에 저장\n",
    "    try:\n",
    "        with open('C:/Users/aischool/FlaskTest/static/thesis/combined_text2.txt', 'r', encoding='utf-8') as file:\n",
    "            additional_info2 = file.read()\n",
    "    except Exception as e:\n",
    "        additional_info2 = \"참조 문서를 불러오는 데 실패했습니다.\"\n",
    "\n",
    "    # OpenAI API 키 설정\n",
    "    openai.api_key = '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'\n",
    "\n",
    "    # GPT-4를 호출하여 사용자 메시지와 추가 정보에 대한 응답 생성\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"당신은 HTP 심리검사에 대한 전문적인 지식을 가진 상담가입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "                {\"role\": \"assistant\", \"content\": additional_info + \"\\n\\n\" + additional_info2}  # 두 가지 추가 정보 포함\n",
    "            ],\n",
    "            max_tokens=400,\n",
    "            temperature=0.3,\n",
    "            presence_penalty=0.0,\n",
    "            frequency_penalty=0.0,\n",
    "            stop=[\"\\n\"]\n",
    "        )\n",
    "\n",
    "        gpt_response = response.choices[0].message['content']\n",
    "        return jsonify({'reply': gpt_response})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "gpt4_interpretations = {}\n",
    "\n",
    "\n",
    "# 파일 업로드\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        app.logger.error('No file part in the request')\n",
    "        return jsonify({'message': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        app.logger.error('No selected file for uploading')\n",
    "        return jsonify({'message': 'No selected file'}), 400\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = generate_unique_filename(file.filename)\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(file_path)\n",
    "\n",
    "        # 이미지 처리\n",
    "        results_json = process_image(file_path)\n",
    "\n",
    "        json_path = os.path.join(app.config['UPLOAD_FOLDER'], f\"{filename}.json\")\n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(results_json)\n",
    "\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "        natural_language_data = convert_json_to_natural_language(json_data)\n",
    "\n",
    "        api_key = '-'\n",
    "        reference_file_path = 'C:/Users/aischool/FlaskTest/static/thesis/combined_text2.txt'\n",
    "        gpt_result = gpt4_turbo_interpret(natural_language_data, api_key, reference_file_path)\n",
    "\n",
    "        \n",
    "        # GPT-4 해석 결과 저장\n",
    "        username = request.form['username']\n",
    "        gpt4_interpretations[username] = gpt_result\n",
    "    \n",
    "        # 이미지를 BLOB으로 변환\n",
    "        image_blob = convert_image_to_blob(file_path)\n",
    "\n",
    "        # 데이터베이스에 저장\n",
    "        try:\n",
    "            new_test_result = TestResult(\n",
    "                TEST_RESULT=gpt_result,\n",
    "                TEST_TYPE=request.form['testType'],\n",
    "                USERNAME=request.form['username'],  # 실제 회원 ID로 대체\n",
    "                TEST_IMG=image_blob  # 이미지 BLOB 저장\n",
    "            )\n",
    "            db.session.add(new_test_result)\n",
    "            db.session.commit()\n",
    "        except Exception as e:\n",
    "            app.logger.error(f\"Error during file upload: {e}\", exc_info=True)\n",
    "            return jsonify({'error': str(e)}), 500\n",
    "\n",
    "        return jsonify({'message': 'File uploaded and processed successfully'}), 200\n",
    "\n",
    "    else:\n",
    "        app.logger.error('File type not allowed')\n",
    "        return jsonify({'message': 'File type not allowed'}), 400\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd6653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
